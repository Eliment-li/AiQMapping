
env_version: 12
reward_function_version: 5
circuit_path: data/circuits/xeb
###Iters is the number of batches the model will train on and the number of times your model weights will be updated (not counting minibatches).
stop_iters: 2

lr: 3.0e-5
lr_grid: [5.0e-5, 3.0e-5]
gamma: 0.99
gamma_grid: [0.99, 0.8]
fcnet_activation: [Swish]
fcnet_hiddens: [128,256,256,128]

#One call to env.step() is one timestep.
stop_timesteps: 99999999

#the reward for multi-agent is the total sum (not the mean) over the agents.
stop_reward: 100

no_tune: False
local_mode: False
framework: torch
checkpoint_frequency: 10
checkpoint_at_end: True

qasm: None
log_file_id: 0



run: PPO
#在config.py中有自动配置
num_gpus: 1
#resume: False
checkpoint: None

#the save path of check_point zip file
check_point_zip_path: None

debug: False


explore_during_inference: False
#attention start
use_attention: True

# The number of transformer units within GTrXL.
# A transformer unit in GTrXL consists of :
# a) MultiHeadAttention module and
# b) a position-wise MLP.
attention_num_transformer_units: 1

# The number of attention heads within the MultiHeadAttention units.
attention_num_heads: 1
# The dim of a single head (within the MultiHeadAttention units).
attention_head_dim: 32

# Whether to feed a_{t-n:t-1} to GTrXL (one-hot encoded if discrete).
prev_n_actions: 0
# Whether to feed r_{t-n:t-1} to GTrXL.
prev_n_rewards: 0
 # The input and output size of each transformer unit.
attention_dim: 32

# The memory sizes for inference and training.
attention_memory_inference: 10
attention_memory_training: 10

# The output dim of the position-wise MLP.
attention_position_wise_mlp_dim: 32
# The initial bias values for the 2 GRU gates within a transformer unit.
attention_init_gru_gate_bias: 2.0

#attention end



#unimportant
plot_trace: False
plot_result: False
storage_path: ' '